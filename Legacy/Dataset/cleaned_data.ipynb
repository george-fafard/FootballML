{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sportsipy in /opt/anaconda3/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: pandas>=0.24.1 in /opt/anaconda3/lib/python3.8/site-packages (from sportsipy) (1.1.3)\n",
      "Requirement already satisfied: pyquery>=1.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from sportsipy) (1.4.3)\n",
      "Requirement already satisfied: requests>=2.18.4 in /opt/anaconda3/lib/python3.8/site-packages (from sportsipy) (2.24.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.1->sportsipy) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.1->sportsipy) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.1->sportsipy) (2020.1)\n",
      "Requirement already satisfied: lxml>=2.1 in /opt/anaconda3/lib/python3.8/site-packages (from pyquery>=1.4.0->sportsipy) (4.6.1)\n",
      "Requirement already satisfied: cssselect>0.7.9 in /opt/anaconda3/lib/python3.8/site-packages (from pyquery>=1.4.0->sportsipy) (1.1.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.18.4->sportsipy) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.18.4->sportsipy) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.18.4->sportsipy) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.18.4->sportsipy) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.1->sportsipy) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sportsipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats from dataset\n",
    "from sportsipy.nfl.boxscore import Boxscores, Boxscore\n",
    "\n",
    "# Required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "# sklearn utilities\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# sklearn models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to get the data from a certain year and returns a DataFrame\n",
    "#@param int year representing the year you wan't to get the data from\n",
    "#@return A dataframe containing the data.\n",
    "def game_data_from_year(year):\n",
    "    returnDF=pd.DataFrame()\n",
    "    try: \n",
    "        #goes through the year getting each week of games\n",
    "        for week in range(1,22):\n",
    "            weekDF=pd.DataFrame()\n",
    "            #goes through each week getting each game\n",
    "            for game in range(len(Boxscores(week,year).games[str(week)+\"-\"+str(year)])):\n",
    "                weekDF=pd.concat([weekDF,Boxscore(Boxscores(week,year).games[str(week)+\"-\"+str(year)][game]['boxscore']).dataframe])\n",
    "            weekDF[\"week\"] = [week]*len(Boxscores(week,year).games[str(week)+\"-\"+str(year)])\n",
    "            returnDF=pd.concat([returnDF,weekDF])\n",
    "    except:\n",
    "        print(week)\n",
    "    return returnDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets the data from the 2000's and saves it to files so you don't have to rerun this code in the future\n",
    "#because this code takes a while to run\n",
    "data2000=game_data_from_year(2000)\n",
    "data2000.to_csv(\"data2000.csv\")\n",
    "data2001=game_data_from_year(2001)\n",
    "data2001.to_csv(\"data2001.csv\")\n",
    "data2002=game_data_from_year(2002)\n",
    "data2002.to_csv(\"data2002.csv\")\n",
    "data2003=game_data_from_year(2003)\n",
    "data2003.to_csv(\"data2003.csv\")\n",
    "data2004=game_data_from_year(2004)\n",
    "data2004.to_csv(\"data2004.csv\")\n",
    "data2005=game_data_from_year(2005)\n",
    "data2005.to_csv(\"data2005.csv\")\n",
    "data2006=game_data_from_year(2006)\n",
    "data2006.to_csv(\"data2006.csv\")\n",
    "data2007=game_data_from_year(2007)\n",
    "data2007.to_csv(\"data2007.csv\")\n",
    "data2008=game_data_from_year(2008)\n",
    "data2008.to_csv(\"data2008.csv\")\n",
    "data2009=game_data_from_year(2009)\n",
    "data2009.to_csv(\"data2009.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets the data from the 2010's and saves it to files again\n",
    "data2010=game_data_from_year(2010)\n",
    "data2010.to_csv(\"data2010.csv\")\n",
    "data2011=game_data_from_year(2011)\n",
    "data2011.to_csv(\"data2011.csv\")\n",
    "data2012=game_data_from_year(2012)\n",
    "data2012.to_csv(\"data2012.csv\")\n",
    "data2013=game_data_from_year(2013)\n",
    "data2013.to_csv(\"data2013.csv\")\n",
    "data2014=game_data_from_year(2014)\n",
    "data2014.to_csv(\"data2014.csv\")\n",
    "data2015=game_data_from_year(2015)\n",
    "data2015.to_csv(\"data2015.csv\")\n",
    "data2016=game_data_from_year(2016)\n",
    "data2016.to_csv(\"data2016.csv\")\n",
    "data2017=game_data_from_year(2017)\n",
    "data2017.to_csv(\"data2017.csv\")\n",
    "data2018=game_data_from_year(2018)\n",
    "data2018.to_csv(\"data2018.csv\")\n",
    "data2019=game_data_from_year(2019)\n",
    "data2019.to_csv(\"data2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/alexandertownsend/Downloads/FootballML/Legacy/Dataset/data2000.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a8a0df9ba083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata200\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata200\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/data200'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/alexandertownsend/Downloads/FootballML/Legacy/Dataset/data2000.csv'"
     ]
    }
   ],
   "source": [
    "#reads in the data from the files for the 2000's and stores it in a list of dataframes\n",
    "data200=[]\n",
    "for i in range(10):\n",
    "    data200.append(pd.read_csv(os.getcwd() + '/data200'+str(i)+'.csv', header=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads in the data from the files for the 2010's and stores it in a list of dataframes\n",
    "data201=[]\n",
    "for i in range(10):\n",
    "    data201.append(pd.read_csv(os.getcwd() + '/data201'+str(i)+'.csv', header=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFL team abbreviations\n",
    "teams=['NOR', 'MIN', 'CHI', 'DET', 'MIA', 'BUF', 'TAM', 'CLE', 'PIT', 'ATL', 'OTI', 'RAI', 'NWE', 'CIN', 'HTX', 'CLT', 'JAX', 'DEN', 'NYG', 'CAR', 'CRD', 'RAM', 'SEA', 'SFO', 'GNB', 'PHI', 'WAS', 'DAL', 'RAV', 'NYJ', 'KAN', 'SDG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the columns that are produced by clean data: \n",
    "#'attendance','first_downs','fourth_down_attempts','fourth_down_conversions','fumbles','fumbles_lost','interceptions',\n",
    "#'net_pass_yards','pass_attempts','pass_completions','pass_touchdowns','pass_yards','penalties','points','rush_attempts',\n",
    "#'rush_touchdowns','rush_yards','third_down_attempts','third_down_conversions','time_of_possession','times_sacked',\n",
    "#'total_yards','turnovers','yards_from_penalties','yards_lost_from_sacks','duration','roof','surface',\n",
    "#'time','temperature','humidity','wind','week','win'\n",
    "\n",
    "#splits all the games into stats for the away team and home team and saves them in the list at the index designated for that team\n",
    "#with the first column in each team representing home games and the 2nd column representing away\n",
    "#@param newdata being a dataframe containing games\n",
    "#@return a list of      lists     of lists\n",
    "#          team      home vs away    stats for the game for that team\n",
    "def cleandata(newdata):\n",
    "    #makes a list to hold all the data of the right dimensions where each index is a team and in each of those lists, \n",
    "    #0 inicates a home game and 1 indicates away\n",
    "    teamdata = []\n",
    "    for team in teams:\n",
    "        teamdata.append([[],[]])\n",
    "\n",
    "    #loops through all the games that one would get from \n",
    "    for game in newdata:\n",
    "        g=list(game)\n",
    "        \n",
    "        #determines if the away team won or lost\n",
    "        if g[62]=='Away':\n",
    "            \n",
    "            #index [1] attendance\n",
    "            #indices [2:26] all away team game stats\n",
    "            #index [28] durration\n",
    "            #index [29:53]\n",
    "            #index [56] roof\n",
    "            #index [58:60] surface, time\n",
    "            #index [61] weather\n",
    "            #index [-1] week\n",
    "            \n",
    "            #if the away team won, then we add a 1 to the end of the team 1 which is the away team, \n",
    "            #and 0 to the end of team 2, to indicate if that was a win or loss for each team.\n",
    "            team1=g[1:20]+[int(g[20][0:2])+float(g[20][3:5])/60]+g[21:26]+([int(g[28].split(\":\")[0])+float(g[28].split(\":\")[1])/60] if not isinstance(g[28],float) else [3])+[g[56]]+g[58:60]+[g[61]]+[g[-1]]+[1]\n",
    "            team2=[g[1]]+g[29:47]+[int(g[47][0:2])+float(g[47][3:5])/60]+g[48:53]+([int(g[28].split(\":\")[0])+float(g[28].split(\":\")[1])/60] if not isinstance(g[28],float) else [3])+[g[56]]+g[58:60]+[g[61]]+[g[-1]]+[0]\n",
    "\n",
    "\n",
    "            #next take all the strings and transform them into some int/double so we have a list of just numbers\n",
    "            team1[26]=  (1 if team1[26]=='Outdoors' else 0)\n",
    "            team2[26]=  (1 if team2[26]=='Outdoors' else 0)\n",
    "            team1[27]=  (1 if team1[27]=='Grass' else 0)\n",
    "            team2[27]=  (1 if team2[27]=='Grass' else 0)\n",
    "            team1[28]=  (int(team1[28].split(\":\")[0])+12 if team1[28].split(\":\")[1][2:4]==\"pm\" else int(team1[28].split(\":\")[0])) + float(team1[28].split(\":\")[1][0:2])/60\n",
    "            team2[28]=  (int(team2[28].split(\":\")[0])+12 if team2[28].split(\":\")[1][2:4]==\"pm\" else int(team2[28].split(\":\")[0])) + float(team2[28].split(\":\")[1][0:2])/60\n",
    "\n",
    "            \n",
    "            #break up weather into just it's component values, dealing with nan by replacing them with the averages as \n",
    "            #calulated from some year\n",
    "            weather1=[]\n",
    "            if isinstance(team1[29],float):\n",
    "                weather1=[55,0.5,9]\n",
    "            elif len(team1[29].split(\" \"))>6:\n",
    "                weather1=[int(team1[29].split(\" \")[0]),float(team1[29].split(\" \")[4][0:-2])/100, (0 if team1[29].split(\" \")[6]=='wind,' or team1[29].split(\" \")[6]=='wind' else  int(team1[29].split(\" \")[6]))]\n",
    "            else: \n",
    "                weather1=[int(team1[29].split(\" \")[0]),.50, (0 if team1[29].split(\" \")[3]=='wind,' or team1[29].split(\" \")[3]=='wind' else  int(team1[29].split(\" \")[3]))]\n",
    "\n",
    "\n",
    "            weather2=[]\n",
    "            if isinstance(team2[29],float):\n",
    "                weather2=[55,0.5,9]\n",
    "            elif len(team2[29].split(\" \"))>6:\n",
    "                weather2=[int(team2[29].split(\" \")[0]),float(team2[29].split(\" \")[4][0:-2])/100, (0 if team2[29].split(\" \")[6]=='wind,' or team2[29].split(\" \")[6]=='wind' else  int(team2[29].split(\" \")[6]))]\n",
    "            else: \n",
    "                weather2=[int(team2[29].split(\" \")[0]),.50, (0 if team2[29].split(\" \")[3]=='wind,' or team2[29].split(\" \")[3]=='wind' else  int(team2[29].split(\" \")[3]))]\n",
    "\n",
    "\n",
    "            \n",
    "            team1=team1[0:29]+weather1+team1[30:32]\n",
    "            team2=team2[0:29]+weather2+team2[30:32]\n",
    "\n",
    "            \n",
    "            #since the wining team is away when we look at the winning abreviation at 63 we are looking at the \n",
    "            #away abreviation and so we store it in the away list for that team\n",
    "            teamdata[teams.index(g[63])][1].append(team1)\n",
    "            teamdata[teams.index(g[53])][0].append(team2)\n",
    "        else:\n",
    "            ##Mostly the same comments except for a few changes, here the 1 and 0 are in oposite spots because the home team won\n",
    "            team1=g[1:20]+[int(g[20][0:2])+float(g[20][3:5])/60]+g[21:26]+([int(g[28].split(\":\")[0])+float(g[28].split(\":\")[1])/60] if not isinstance(g[28],float) else [3])+[g[56]]+g[58:60]+[g[61]]+[g[-1]]+[0]\n",
    "            team2=[g[1]]+g[29:47]+[int(g[47][0:2])+float(g[47][3:5])/60]+g[48:53]+([int(g[28].split(\":\")[0])+float(g[28].split(\":\")[1])/60] if not isinstance(g[28],float) else [3])+[g[56]]+g[58:60]+[g[61]]+[g[-1]]+[1]\n",
    "\n",
    "\n",
    "\n",
    "            team1[26] = (1 if team1[26]=='Outdoors' else 0)\n",
    "            team2[26]=  (1 if team2[26]=='Outdoors' else 0)\n",
    "            team1[27]=  (1 if team1[27]=='Grass' else 0)\n",
    "            team2[27]=  (1 if team2[27]=='Grass' else 0)\n",
    "            team1[28]=  (int(team1[28].split(\":\")[0])+12 if team1[28].split(\":\")[1][2:4]==\"pm\" else int(team1[28].split(\":\")[0])) + float(team1[28].split(\":\")[1][0:2])/60\n",
    "            team2[28]=  (int(team2[28].split(\":\")[0])+12 if team2[28].split(\":\")[1][2:4]==\"pm\" else int(team2[28].split(\":\")[0])) + float(team2[28].split(\":\")[1][0:2])/60\n",
    "\n",
    "            \n",
    "            \n",
    "            weather1=[]\n",
    "            if isinstance(team1[29],float):\n",
    "                weather1=[55,0.5,9]\n",
    "            elif len(team1[29].split(\" \"))>6:\n",
    "                weather1=[int(team1[29].split(\" \")[0]),float(team1[29].split(\" \")[4][0:-2])/100, (0 if team1[29].split(\" \")[6]=='wind,' or team1[29].split(\" \")[6]=='wind' else  int(team1[29].split(\" \")[6]))]\n",
    "            else: \n",
    "                weather1=[int(team1[29].split(\" \")[0]),.50, (0 if team1[29].split(\" \")[3]=='wind,' or team1[29].split(\" \")[3]=='wind' else  int(team1[29].split(\" \")[3]))]\n",
    "\n",
    "\n",
    "            weather2=[]\n",
    "            if isinstance(team2[29],float):\n",
    "                weather2=[55,0.5,9]\n",
    "            elif len(team2[29].split(\" \"))>6:\n",
    "                weather2=[int(team2[29].split(\" \")[0]),float(team2[29].split(\" \")[4][0:-2])/100, (0 if team2[29].split(\" \")[6]=='wind,' or team2[29].split(\" \")[6]=='wind' else  int(team2[29].split(\" \")[6]))]\n",
    "            else: \n",
    "                weather2=[int(team2[29].split(\" \")[0]),.50, (0 if team2[29].split(\" \")[3]=='wind,' or team2[29].split(\" \")[3]=='wind' else  int(team2[29].split(\" \")[3]))]\n",
    "\n",
    "    \n",
    "                \n",
    "            team1=team1[0:29]+weather1+team1[30:32]\n",
    "            team2=team2[0:29]+weather2+team2[30:32]\n",
    "\n",
    "\n",
    "            ##and here a few things are switched up to get things to be stored at the right spots.\n",
    "            teamdata[teams.index(g[63])][0].append(team2)\n",
    "            teamdata[teams.index(g[53])][1].append(team1)\n",
    "    return teamdata\n",
    "\n",
    "\n",
    "#These are the columns produced by getTraining\n",
    "#'away_average_attendance', 'away_average_first_downs', 'away_average_fourth_down_attempts', 'away_average_fourth_down_conversions', 'away_average_fumbles', 'away_average_fumbles_lost', 'away_average_interceptions', 'away_average_net_pass_yards', 'away_average_pass_attempts', 'away_average_pass_completions', 'away_average_pass_touchdowns', 'away_average_pass_yards', 'away_average_penalties', 'away_average_points', 'away_average_rush_attempts', 'away_average_rush_touchdowns', 'away_average_rush_yards', 'away_average_third_down_attempts', 'away_average_third_down_conversions', 'away_average_time_of_possession', 'away_average_times_sacked', 'away_average_total_yards', 'away_average_turnovers', 'away_average_yards_from_penalties', 'away_average_yards_lost_from_sacks', 'away_average_duration', 'away_average_roof', 'away_average_surface', 'away_average_time', 'away_average_temperature', 'away_average_humidity', 'away_average_wind', 'away_average_week', 'away_average_win'\n",
    "#'home_average_attendance', 'home_average_first_downs', 'home_average_fourth_down_attempts', 'home_average_fourth_down_conversions', 'home_average_fumbles', 'home_average_fumbles_lost', 'home_average_interceptions', 'home_average_net_pass_yards', 'home_average_pass_attempts', 'home_average_pass_completions', 'home_average_pass_touchdowns', 'home_average_pass_yards', 'home_average_penalties', 'home_average_points', 'home_average_rush_attempts', 'home_average_rush_touchdowns', 'home_average_rush_yards', 'home_average_third_down_attempts', 'home_average_third_down_conversions', 'home_average_time_of_possession', 'home_average_times_sacked', 'home_average_total_yards', 'home_average_turnovers', 'home_average_yards_from_penalties', 'home_average_yards_lost_from_sacks', 'home_average_duration', 'home_average_roof', 'home_average_surface', 'home_average_time', 'home_average_temperature', 'home_average_humidity', 'home_average_wind', 'home_average_week', 'home_average_win'\n",
    "#'roof', 'surface', 'time', 'temperature', 'humidity', 'wind'\n",
    "\n",
    "\n",
    "#takes data from games and calculates the averages for the games before that game for each team in that \n",
    "#season+3games from the previous season, taking into account\n",
    "#home vs away, and also takes the stats about the game that we could know about the game before it happens like\n",
    "#the weather and location\n",
    "#@param data2014 data for the previous year, gotten from cleandata\n",
    "#@param data2015 data for the year in question, gotten from cleandata\n",
    "#@param games The raw data for the year in question\n",
    "#@return x,y where x has the columns listed above and y has 1 for home team win and 0 for away team win.\n",
    "def getTraining(data2014,data2015,games, year):\n",
    "    #So first I make a list of counters to keep track of how many times we have seen each team, with home vs away built in.\n",
    "    counters=[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]\n",
    "    trainingX=[]\n",
    "    trainingY=[]\n",
    "    \n",
    "    madePlayoffs=[]\n",
    "    for i in teams:\n",
    "        madePlayoffs.append(0)\n",
    "        \n",
    "    for i in range(len(teams)):\n",
    "        for j in range(2):\n",
    "            for g in data2014[i][j]:\n",
    "                if g[-2]>=18:\n",
    "                    madePlayoffs[i]=1\n",
    "        \n",
    "    #next we cycle through the games for a specific year\n",
    "    for game in range(len(games)):\n",
    "        g=list(games[game])\n",
    "        \n",
    "        if(int(g[-1])<17):\n",
    "            #get the teams playing for that game\n",
    "            if g[62]=='Away':\n",
    "                awayabbr=g[63]\n",
    "                homeabbr=g[53]\n",
    "                win=0\n",
    "            else:\n",
    "                awayabbr=g[53]\n",
    "                homeabbr=g[63]\n",
    "                win=1\n",
    "\n",
    "\n",
    "            #get the sum of the three games from the end of the last season, keeping attention to home vs away\n",
    "            averagesA=[]+data2014[teams.index(awayabbr)][1][-3]\n",
    "            for i in range(len(averagesA)):\n",
    "                averagesA[i]+=data2014[teams.index(awayabbr)][1][-2][i]+data2014[teams.index(awayabbr)][1][-1][i]\n",
    "\n",
    "            #add the totals for this season up to this game, keeping attention to home vs away\n",
    "            #this is where the counter play in since they keep us from going to the current game info and future game infos\n",
    "            for i in range(counters[teams.index(awayabbr)][1]):\n",
    "                for j in range(len(data2015[teams.index(awayabbr)][1][i])):\n",
    "                    averagesA[i]+=data2015[teams.index(awayabbr)][1][i][j]\n",
    "\n",
    "\n",
    "\n",
    "            ##same for the home team\n",
    "            averagesH=[]+data2014[teams.index(homeabbr)][0][-3]\n",
    "            for i in range(len(averagesH)):\n",
    "                averagesH[i]+=data2014[teams.index(homeabbr)][0][-2][i]+data2014[teams.index(homeabbr)][0][-1][i]\n",
    "            for i in range(counters[teams.index(homeabbr)][0]):\n",
    "                for j in range(len(data2015[teams.index(homeabbr)][0][i])):\n",
    "                    averagesH[i]+=data2015[teams.index(homeabbr)][0][i][j]\n",
    "\n",
    "            #update counters for these teams\n",
    "            Ai=teams.index(awayabbr)\n",
    "            Hi=teams.index(homeabbr)\n",
    "            counters[Ai][1]+=1\n",
    "            counters[Hi][0]+=1\n",
    "\n",
    "            #get the info about the game we could know before hand by getting the info for the game as we did in cleaned data\n",
    "            team1=g[1:20]+[int(g[20][0:2])+float(g[20][3:5])/60]+g[21:26]+([int(g[28].split(\":\")[0])+float(g[28].split(\":\")[1])/60] if not isinstance(g[28],float) else [3])+[g[56]]+g[58:60]+[g[61]]+[g[-1]]+[0]\n",
    "\n",
    "\n",
    "            venue=  (1 if team1[26]=='Outdoors' else 0)\n",
    "            field=  (1 if team1[27]=='Grass' else 0)\n",
    "            time=  (int(team1[28].split(\":\")[0])+12 if team1[28].split(\":\")[1][2:4]==\"pm\" else int(team1[28].split(\":\")[0])) + float(team1[28].split(\":\")[1][0:2])/60\n",
    "\n",
    "\n",
    "\n",
    "            weather1=[]\n",
    "            if isinstance(team1[29],float):\n",
    "                weather1=[55,0.5,9]\n",
    "            elif len(team1[29].split(\" \"))>6:\n",
    "                weather1=[int(team1[29].split(\" \")[0]),float(team1[29].split(\" \")[4][0:-2])/100, (0 if team1[29].split(\" \")[6]=='wind,' or team1[29].split(\" \")[6]=='wind' else  int(team1[29].split(\" \")[6]))]\n",
    "            else: \n",
    "                weather1=[int(team1[29].split(\" \")[0]),.50, (0 if team1[29].split(\" \")[3]=='wind,' or team1[29].split(\" \")[3]=='wind' else  int(team1[29].split(\" \")[3]))]\n",
    "\n",
    "\n",
    "            #Add everything to the list of training datas\n",
    "            trainingX.append(averagesH+[counters[Hi][0]]+[madePlayoffs[Hi]]+averagesA+[counters[Ai][1]]+[madePlayoffs[Ai]]+[venue]+[field]+[time]+weather1+[year])\n",
    "            trainingY.append(win)\n",
    "\n",
    "    #return results\n",
    "    return trainingX,trainingY\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#getting the data that we might train models on.\n",
    "\n",
    "xtraining=[]\n",
    "ytraining=[]\n",
    "aveAway=[]\n",
    "aveHome=[]\n",
    "columns=[]\n",
    "for i in range(1,10):\n",
    "    try:\n",
    "        xtraintemp,ytraintemp=getTraining(cleandata(np.array(data201[i-1])),cleandata(np.array(data201[i])),np.array(data201[i]),2010+i)\n",
    "        xtraining+=xtraintemp\n",
    "        ytraining+=ytraintemp\n",
    "    except:\n",
    "        print(i)\n",
    "        \n",
    "    try:\n",
    "        xtraintemp,ytraintemp=getTraining(cleandata(np.array(data200[i-1])),cleandata(np.array(data200[i])),np.array(data200[i]),2000+i)\n",
    "        xtraining+=xtraintemp\n",
    "        ytraining+=ytraintemp\n",
    "    except:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
